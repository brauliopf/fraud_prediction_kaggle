{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set pandas to display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/fraudTrain.csv', dtype={\n",
    "    'merch_lat': str,\n",
    "    'merch_long': str\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Dictionary**\n",
    "\n",
    "- Transaction event data: 'trans_date_trans_time', 'amt', 'unix_time', 'trans_num', 'is_fraud'\n",
    "- Customer: 'cc_num', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat', 'long', 'job', 'dob'\n",
    "- Merchant: 'merchant', 'category', 'merch_lat', 'merch_long', 'city_pop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "## Keep only necessary columns\n",
    "## - Transaction event data: 'trans_date_trans_time', 'amt', 'unix_time', 'is_fraud'\n",
    "## - Customer: 'gender', 'lat', 'long', 'job', 'dob' --keep only lat, long to calculate distance\n",
    "## - Merchant: 'category', 'merch_lat', 'merch_long', 'city_pop'\n",
    "\n",
    "# split features / label\n",
    "features = data.drop('Unnamed: 0', axis=1).drop('is_fraud', axis=1)\n",
    "features = features[['trans_date_trans_time', 'amt', 'unix_time','gender', 'lat', 'long', 'job', 'dob','category', 'merch_lat', 'merch_long', 'city_pop']]\n",
    "label = data['is_fraud']\n",
    "display(features.info())\n",
    "display(features.describe(include='all').T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transaction event data: 'trans_date_trans_time', 'amt', 'unix_time', 'is_fraud'\n",
    "- Customer: 'gender', 'lat', 'long', 'job', 'dob' --keep only lat, long to calculate distance\n",
    "- Merchant: 'category', 'merch_lat', 'merch_long', 'city_pop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "# sns.set_style(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is_fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=data, x=\"is_fraud\")\n",
    "plt.title(\"Distribution of Fraud\")\n",
    "print(data['is_fraud'].value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### amt\n",
    "\n",
    "- amt is severely left-skewed.\n",
    "- amt of fraud transactions  is concentrated below ~1400\n",
    "- fraud transactions are more frequent between 800 and 1100 (use amt as a feature!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"amt of non-fraud\\n\", data.query('is_fraud == 0')['amt'].describe())\n",
    "print(\"\\namt of fraud\\n\", data.query('is_fraud == 1')['amt'].describe())\n",
    "\n",
    "sns.boxplot(data=data.query('is_fraud == 1'), x=\"amt\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for the amt column\n",
    "data['amt_bins'] = pd.cut(data['amt'], bins=[0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, float('inf')])\n",
    "\n",
    "# Calculate fraud rate for each bin\n",
    "fraud_count = data.groupby('amt_bins')['is_fraud'].count().reset_index(name=\"fraud_count\")\n",
    "fraud_rate = data.groupby('amt_bins')['is_fraud'].mean().reset_index(name=\"fraud_rate\")\n",
    "\n",
    "# Plot the fraud rate\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='amt_bins', y='fraud_rate', data=fraud_rate)\n",
    "plt.title('Fraud Rate by Transaction Amount')\n",
    "plt.xlabel('Transaction Amount Bins')\n",
    "plt.ylabel('Fraud Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trans_date_trans_time\n",
    "\n",
    "Notes: frauds happen all year long, but there are some weeks with more frauds than others, with some variation but nothing critical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract weeks\n",
    "data['trans_date_trans_time'] = pd.to_datetime(data['trans_date_trans_time'], errors='coerce')\n",
    "data['date_week'] = data['trans_date_trans_time'].dt.to_period('W')\n",
    "\n",
    "# Group by date and calculate count of transactions\n",
    "daily_count = data.groupby(['date_week', 'is_fraud']).size().reset_index(name=\"count\")\n",
    "\n",
    "# Convert 'date' to datetime for proper plotting\n",
    "daily_count['date_week'] = daily_count['date_week'].dt.to_timestamp()\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Create a line plot\n",
    "sns.lineplot(data=daily_count, x='date_week', y='count', hue='is_fraud')\n",
    "\n",
    "# Customize the plot\n",
    "plt.yscale('log')\n",
    "plt.title('Transaction Count by Week')\n",
    "plt.xlabel('Date (Week)')\n",
    "plt.ylabel('Average Count')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender\n",
    "sns.countplot(data=data, x=\"gender\", hue=\"is_fraud\")\n",
    "plt.title(\"Distribution of Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'lat', 'long'\n",
    "sns.scatterplot(data=data, x=\"lat\", y=\"long\", hue=\"is_fraud\")\n",
    "plt.title(\"Distribution of Latitude and Longitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Convert decimal degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    r = 6371  # Radius of Earth in kilometers\n",
    "    return r * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features_names = ['trans_week', 'amt', 'gender_male', 'distance_cust_merchant', 'fraud_rate_job', 'yob', 'city_pop']\n",
    "\n",
    "features['trans_week'] = pd.to_datetime(features['trans_date_trans_time']).apply(lambda x: x.week)\n",
    "features['gender_male']= features['gender'].map({'F': 0, 'M': 1})\n",
    "features['distance_cust_merchant'] = features.apply(lambda row: haversine(\n",
    "    float(row['lat']), float(row['long']), \n",
    "    float(row['merch_lat']), float(row['merch_long'])\n",
    "), axis=1)\n",
    "fraud_rate_job = data.groupby('job')['is_fraud'].mean().reset_index(name=\"fraud_rate_job\")\n",
    "features['fraud_rate_job'] = features['job'].map(fraud_rate_job.set_index('job')['fraud_rate_job'])\n",
    "features['yob'] = pd.to_datetime(features['dob'], errors='coerce').dt.to_period('Y')\n",
    "features['yob'] = features['yob'].apply(lambda x: int(x.strftime('%Y')))\n",
    "\n",
    "model_features = features[model_features_names]\n",
    "model_features['yob'] = model_features['yob'].apply(lambda x: int(x.strftime('%Y')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and scale\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(model_features, label, test_size=0.1, random_state=14)\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test):\n",
    "  model.fit(X_train, y_train)\n",
    "  y_pred = model.predict(X_test)\n",
    "  accuracy = accuracy_score(y_test,y_pred)\n",
    "  print(f'{model.__class__.__name__} Accuracy: {accuracy:.4f}')\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lrg_model = LogisticRegression()\n",
    "train_and_evaluate(lrg_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgb_model = XGBClassifier(random_state=14, eta=0.9)\n",
    "train_and_evaluate(xgb_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=14)\n",
    "\n",
    "X_resampled, y_resampled, = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "train_and_evaluate(xgb_model, X_resampled, X_test, y_resampled, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
